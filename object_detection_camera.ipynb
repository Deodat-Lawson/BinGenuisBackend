{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Object Detection Setup For Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = r'C:\\Users\\timot\\OneDrive - Johns Hopkins\\hackathonProject\\models\\research\\hackathonModel.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the training data, ignore when running the actual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = r'C:\\Users\\timot\\OneDrive - Johns Hopkins\\hackathonProject\\models\\research\\dataset-resized'\n",
    "\n",
    "train = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
    "validation = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
    "train_dataset = train.flow_from_directory(DATA_DIR, target_size=(224,224), batch_size = 32, class_mode = 'categorical', subset= 'training')\n",
    "validation_dataset = validation.flow_from_directory(DATA_DIR, target_size=(224,224), batch_size = 32, class_mode = 'categorical', subset= 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "\n",
    "base_model.trainable = False\n",
    "inputs = tf.keras.Input(shape=(224,224, 3))\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_dataset)\n",
    "print(x_batch.shape)  # Should print (32, 512, 384, 3) based on your input size and batch size\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])\n",
    "history_fine = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell if the model is already trained. If just finished training the model, run the save cell before running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir)\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perdicting a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dir = r'C:\\Users\\timot\\OneDrive - Johns Hopkins\\hackathonProject\\models\\research\\imagedata'\n",
    "classarr = [\"Cardboard\",\"Glass\",\"Metal\",\"Paper\",\"Plastic\",\"Trash\"]\n",
    "\n",
    "n = 0\n",
    "for i in os.listdir(test_dir):\n",
    "    thisImage = image.load_img(test_dir + '//' + i, target_size=(224,224))\n",
    "    img_array = image.img_to_array(thisImage)\n",
    "    img_ready = np.expand_dims(img_array, axis=0)\n",
    "    predictions = model.predict(img_ready)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    \n",
    "    if classarr[predicted_class] == \"Metal\":\n",
    "        print(f\"Predicted class: Metal, item: {i}\")\n",
    "    elif classarr[predicted_class] == \"Paper\" or classarr[predicted_class] == \"Cardboard\":\n",
    "        print(f\"Predicted class: Paper or Cardboard, item: {i}\")\n",
    "    elif classarr[predicted_class] == \"Plastic\" or classarr[predicted_class] == \"Glass\":\n",
    "        print(f\"Predicted class: Plastic or Glass, item: {i}\")\n",
    "    else:\n",
    "        print(f\"Predicted class: Trash, item: {i}\")\n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Detect Objects with OpenCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), 'data')\n",
    "MODELS_DIR = os.path.join(DATA_DIR, 'models')\n",
    "for dir in [DATA_DIR, MODELS_DIR]:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "After testing we decided that centernet_resnet50_v2_512x512_coco17_tpu-8 is the best option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Download and extract model\n",
    "MODEL_DATE = '20200711'\n",
    "MODEL_NAME = 'centernet_resnet50_v2_512x512_coco17_tpu-8'\n",
    "MODEL_TAR_FILENAME = MODEL_NAME + '.tar.gz'\n",
    "MODELS_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
    "MODEL_DOWNLOAD_LINK = MODELS_DOWNLOAD_BASE + MODEL_DATE + '/' + MODEL_TAR_FILENAME\n",
    "print(MODEL_DOWNLOAD_LINK)\n",
    "PATH_TO_MODEL_TAR = os.path.join(MODELS_DIR, MODEL_TAR_FILENAME)\n",
    "PATH_TO_CKPT = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'checkpoint/'))\n",
    "PATH_TO_CFG = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, 'pipeline.config'))\n",
    "if not os.path.exists(PATH_TO_CKPT):\n",
    "    print('Downloading model. This may take a while... ', end='')\n",
    "    urllib.request.urlretrieve(MODEL_DOWNLOAD_LINK, PATH_TO_MODEL_TAR)\n",
    "    tar_file = tarfile.open(PATH_TO_MODEL_TAR)\n",
    "    tar_file.extractall(MODELS_DIR)\n",
    "    tar_file.close()\n",
    "    os.remove(PATH_TO_MODEL_TAR)\n",
    "    print('Done')\n",
    "\n",
    "# Download labels file\n",
    "LABEL_FILENAME = 'mscoco_label_map.pbtxt'\n",
    "LABELS_DOWNLOAD_BASE = \\\n",
    "    'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
    "PATH_TO_LABELS = os.path.join(MODELS_DIR, os.path.join(MODEL_NAME, LABEL_FILENAME))\n",
    "if not os.path.exists(PATH_TO_LABELS):\n",
    "    print('Downloading label file... ', end='')\n",
    "    urllib.request.urlretrieve(LABELS_DOWNLOAD_BASE + LABEL_FILENAME, PATH_TO_LABELS)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "Next we load the downloaded model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "\n",
    "# # Enable GPU dynamic memory allocation\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label map data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from PIL import UnidentifiedImageError\n",
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "outputPredicted = False\n",
    "Threshold = 0\n",
    "    \n",
    "while True:\n",
    "#     for i in os.listdir(test_dir):\n",
    "#         if i == '0.png':\n",
    "#             try:\n",
    "#                 os.remove(test_dir + '/0.png')\n",
    "#             except PermissionError:\n",
    "#                 print(f\"Permission denied for {item_path}.\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error removing {item_path}: {e}\")\n",
    "                \n",
    "            \n",
    "    for i in os.listdir(test_dir):\n",
    "        try:\n",
    "            thisImage = image.load_img(test_dir + '/' + i, target_size=(224,224))\n",
    "        except UnidentifiedImageError:\n",
    "            print(f\"Processing file: {test_dir + '/' + i}\")\n",
    "            print(f\"Unrecognized image format for file: {i}\")\n",
    "            continue\n",
    "\n",
    "        image_np_with_detections = img_array.astype('uint8')\n",
    "        \n",
    "        #expiremental\n",
    "        try:\n",
    "            img = Image.open(test_dir + '/' + i)\n",
    "            img.verify()  # Check if the image is valid\n",
    "        except:\n",
    "            f = 0\n",
    "#             print(\"The image might be corrupted or incomplete.\")\n",
    "            \n",
    "        cvData = cv2.imread(test_dir + '/' + i)\n",
    "#         print(cvData.shape)\n",
    "\n",
    "        thisImage = image.load_img(test_dir + '/' + i, target_size=(224,224))\n",
    "        img_array = image.img_to_array(thisImage)\n",
    "        \n",
    "        image_np_with_detections = cv2.cvtColor(image_np_with_detections, cv2.COLOR_RGB2BGR)\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(img_array, 0), dtype=tf.float32)\n",
    "        detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "        label_id_offset = 1\n",
    "        \n",
    "            \n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np_with_detections,\n",
    "              detections['detection_boxes'][0].numpy(),\n",
    "              (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "              detections['detection_scores'][0].numpy(),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              max_boxes_to_draw=200,\n",
    "              min_score_thresh=0.4,\n",
    "              agnostic_mode=False)\n",
    "\n",
    "#         Display output\n",
    "\n",
    "        cv2.imshow('object detection', cv2.resize(image_np_with_detections,(800,600)))\n",
    "    \n",
    "        \n",
    "        \n",
    "#         cv2.imshow(\"a\",cv2.resize(cvData,(800,600)))\n",
    "#         cv2.waitKey(15)\n",
    "        \n",
    "#         person_indices = np.where((detection_classes == PERSON_CLASS_ID) & (detection_scores > THRESHOLD))\n",
    "#         if person_indices > 0:\n",
    "    \n",
    "        thisImage = image.load_img(test_dir + '/' + i, target_size=(224,224))\n",
    "        img_array = image.img_to_array(thisImage)\n",
    "        image_np_expanded = np.expand_dims(img_array, axis=0)\n",
    "        predictions = model.predict(image_np_expanded)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "#         val = \"Yellow Compost Bin\"\n",
    "#         if classarr[predicted_class] == \"Cardboard\" or classarr[predicted_class] == \"Paper\":\n",
    "#             val = \"Blue Paper Recycling Bin\"\n",
    "#         elif classarr[predicted_class] == \"Plastic\" or classarr[predicted_class] == \"Glass\":\n",
    "#             val = \"Green Bottle Recycling Bin\"\n",
    "#         elif classarr[predicted_class] == \"Metal\":\n",
    "#             val = \"Gray Incinerate Bin\"\n",
    "            \n",
    "        if outputPredicted == False:\n",
    "            predictions = model.predict(image_np_expanded)\n",
    "            print(f\"Predicted class: {classarr[predicted_class]} item: {i}\")\n",
    "            data = {\n",
    "                'predicted_class': {classarr[predicted_class]},\n",
    "                'is_tf': \"True\"\n",
    "            }\n",
    "            r = requests.post(url=\"http://10.203.127.124:5000/return_prompt\",data=data)\n",
    "            outputPredicted = True\n",
    "        \n",
    "        if Threshold >= 10:\n",
    "            os.remove(test_dir + '/' + i)\n",
    "            Threshold = 0\n",
    "            outputPredicted = False\n",
    "        Threshold = Threshold + 1\n",
    "#         plt.imshow(img_array/255)\n",
    "#         plt.show()\n",
    "\n",
    "    \n",
    "#Classification\n",
    "\n",
    "\n",
    "#This function removes the current item\n",
    "\n",
    "\n",
    "\n",
    "#         if threshold >= 100:\n",
    "#             threshold = 0\n",
    "#             for i in os.listdir(test_dir):\n",
    "#                 item_path = os.path.join(test_dir, i)\n",
    "#                 if os.path.isfile(item_path):\n",
    "#                     try:\n",
    "#                         os.remove(item_path)\n",
    "#                     except PermissionError:\n",
    "#                         print(f\"Permission denied for {item_path}.\")\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error removing {item_path}: {e}\")\n",
    "#             outPredicted = False\n",
    "    \n",
    " \n",
    "            \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "#             data = {\n",
    "#                 'predicted_class': classarr[predicted_class]\n",
    "#                 'item': i\n",
    "#             }\n",
    "#             r = requests.post(url=\"http://10.203.127.124:5000/return_prompt\",data=data)\n",
    "            \n",
    "    \n",
    "#     # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "#     image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "#     # Things to try:\n",
    "#     # Flip horizontally\n",
    "#     # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "#     # Convert image to grayscale\n",
    "#     # image_np = np.tile(\n",
    "#     #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "#     detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "#     label_id_offset = 1\n",
    "#     image_np_with_detections = image_np.copy()\n",
    "    \n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#           image_np_with_detections,\n",
    "#           detections['detection_boxes'][0].numpy(),\n",
    "#           (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "#           detections['detection_scores'][0].numpy(),\n",
    "#           category_index,\n",
    "#           use_normalized_coordinates=True,\n",
    "#           max_boxes_to_draw=200,\n",
    "#           min_score_thresh=0.6,\n",
    "#           agnostic_mode=False)\n",
    "\n",
    "#     # Display output\n",
    "#     cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All cells below are for testing/debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Using OpenCV to initialize the webcam\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, image_np = cap.read()\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'][0].numpy(),\n",
    "          (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "          detections['detection_scores'][0].numpy(),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=200,\n",
    "          min_score_thresh=.50,\n",
    "          line_thickness=1,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('ssd_mobilenet', image_np_with_detections)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "            \n",
    "# Release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
